{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-09-07 10:24:31.432259: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-07 10:24:31.432310: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-07 10:24:31.433203: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-07 10:24:32.434815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import polars as pl\n","import pandas as pd\n","import numpy as np\n","import re\n","import itertools\n","from tqdm import tqdm\n","import pickle\n","import time\n","import copy\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import TextDataset, DataCollatorForLanguageModeling\n","from transformers import Trainer, TrainingArguments, GPT2LMHeadModel, GPT2Tokenizer\n","import pickle"]},{"cell_type":"markdown","metadata":{},"source":["#### 読み込むデータパスの指定"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["base_path = \"/kaggle/s3storage/01_public/humob-challenge-2024/\""]},{"cell_type":"markdown","metadata":{},"source":["## Step 2. Model Training\n","GPT2モデルによるFine-Tunningを実施する。  "]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["class HumobDataset(Dataset):\n","    def __init__(self, humob_dataset_path):\n","        super().__init__()\n","\n","        self.uid_list = []\n","        self.data_token = \"<data>\"\n","        self.end_of_text_token = \"</data>\"\n","\n","        # データのロード\n","        self.df = pl.read_csv(humob_dataset_path)\n","        \n","        # UIDごとにデータを加工\n","        self.processed_data = self._process_data()\n","\n","    def _process_data(self):\n","        data_list = []\n","\n","        # UIDごとにグループ化\n","        grouped = self.df.groupby('uid')\n","\n","        for uid, group in grouped:\n","            # UIDを追加\n","            result = []\n","            result.append(f\"{uid}\")\n","\n","            # <|data|> を追加\n","            result.append(self.data_token)\n","\n","            # 日ごとのデータを処理\n","            for day, day_group in group.sort('d').groupby('d'):\n","                # <|dowX|> を追加\n","                dow = f\"<dow{day % 7}>\"\n","                result.append(dow)\n","                \n","                # x, y のデータを連結して追加\n","                movement_data = ''.join(f\"{t},{x}{y}.\" for t, x, y in zip(day_group['timedelta'],day_group['x'], day_group['y']))\n","                result.append(movement_data)\n","                end_dow = f\"</dow{day % 7}>\"\n","                result.append(end_dow)\n","\n","            # 終了トークンの追加\n","            result.append(self.end_of_text_token)\n","            text = \"\".join(result)\n","            data_list.append(text)\n","\n","        return data_list\n","\n","    def __len__(self):\n","        return len(self.processed_data)\n","\n","    def __getitem__(self, idx):\n","        return self.processed_data[idx]"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["def load_data_collator(tokenizer, mlm = False):\n","    data_collator = DataCollatorForLanguageModeling(\n","        tokenizer=tokenizer, \n","        mlm=mlm,\n","    )\n","    return data_collator\n","\n","\n","def train(train_file_path,model_name,\n","          output_dir,\n","          overwrite_output_dir,\n","          per_device_train_batch_size,\n","          num_train_epochs,\n","          save_steps):\n","  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n","  train_dataset = HumobDataset(train_file_path)\n","  data_collator = load_data_collator(tokenizer)\n","\n","  tokenizer.save_pretrained(output_dir)\n","      \n","  model = GPT2LMHeadModel.from_pretrained(model_name)\n","\n","  model.save_pretrained(output_dir)\n","\n","  training_args = TrainingArguments(\n","          output_dir=output_dir,\n","          overwrite_output_dir=overwrite_output_dir,\n","          per_device_train_batch_size=per_device_train_batch_size,\n","          num_train_epochs=num_train_epochs,\n","      )\n","\n","  trainer = Trainer(\n","          model=model,\n","          args=training_args,\n","          data_collator=data_collator,\n","          train_dataset=train_dataset,\n","  )\n","      \n","  trainer.train()\n","  trainer.save_model()"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# you need to set parameters \n","train_file_path = base_path + \"feature/train_cityB_timedelta.csv\"\n","model_name = 'gpt2'\n","output_dir = './'\n","overwrite_output_dir = False\n","per_device_train_batch_size = 1\n","num_train_epochs = 1\n","save_steps = 500"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7d1a14f4dda4410fbbf946186df754ff","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7a90d97c27e4313be364fc41163207d","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"505111007f0f4914ba09fea285e356ce","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8c1591ba4cee4427bb51eab3c751b2ae","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"099a92ab422341609bd16b772bdcd5ec","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# It takes about 30 minutes to train in colab.\n","train(\n","    train_file_path=train_file_path,\n","    model_name=model_name,\n","    output_dir=output_dir,\n","    overwrite_output_dir=overwrite_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    num_train_epochs=num_train_epochs,\n","    save_steps=save_steps\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3. Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def load_model(model_path):\n","    model = GPT2LMHeadModel.from_pretrained(model_path)\n","    return model\n","\n","\n","def load_tokenizer(tokenizer_path):\n","    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n","    return tokenizer\n","\n","\n","def generate_text(sequence, max_length):\n","    model_path = \"/content/drive/MyDrive/result\"\n","    model = load_model(model_path)\n","    tokenizer = load_tokenizer(model_path)\n","    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n","    final_outputs = model.generate(\n","        ids,\n","        do_sample=True,\n","        max_length=max_length,\n","        pad_token_id=model.config.eos_token_id,\n","        top_k=50,\n","        top_p=0.95,\n","    )\n","    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sequence = input() # oil price\n","max_len = int(input()) # 20\n","generate_text(sequence, max_len) # oil price for July June which had been low at as low as was originally stated Prices have since resumed"]},{"cell_type":"markdown","metadata":{},"source":["The following process may be a little more complicated or tedious because you have to write the code one by one, and it takes a long time if you don't have a personal GPU.\n","\n","Then, how about use Ainize's Teachable NLP? Teachable NLP provides an API to use the model so when data is input it will automatically learn quickly.\n","\n","Teachable NLP : [https://ainize.ai/teachable-nlp](https://link.ainize.ai/3tJVRD1)\n","\n","Teachable NLP Tutorial : [https://forum.ainetwork.ai/t/teachable-nlp-how-to-use-teachable-nlp/65](https://link.ainize.ai/3tATaUh)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
